{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMmiX0G4YSvsok6egi8abWW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangjunxiao/PyTorch-Tutorial/blob/main/PyTorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F86Do1_WZ0_z"
      },
      "source": [
        "# PyTorch Introduction\r\n",
        "##### This Tutorial is modified from [University of Washington CSE446](https://courses.cs.washington.edu/courses/cse446/19au/section9.html) and [PyTorch Official Tutorials](https://pytorch.org/tutorials/)\r\n",
        "Tutorial Video [PyTorch Tutorial Channel of Hung-yi Lee](https://www.youtube.com/watch?v=kQeezFrNoOg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eFq6fx9jWUM"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "torch.manual_seed(446)\r\n",
        "np.random.seed(446)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96qBCDfvj2bg"
      },
      "source": [
        "## Tensors and relation to numpy\r\n",
        "\r\n",
        "PyTorch's basic building block, the `tensor` is similar to numpy's `ndarray`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijMx9GXGkCjb",
        "outputId": "7926444c-e349-437c-f56f-95acb77ff642"
      },
      "source": [
        "# we create tensors in a similar way to numpy nd arrays\r\n",
        "x_numpy = np.array([0.1, 0.2, 0.3])\r\n",
        "x_torch = torch.tensor([0.1, 0.2, 0.3])\r\n",
        "print('x_numpy, x_torch')\r\n",
        "print(x_numpy, x_torch)\r\n",
        "print()\r\n",
        "\r\n",
        "# to and from numpy, pytorch\r\n",
        "print('to and from numpy and pytorch')\r\n",
        "print(torch.from_numpy(x_numpy), x_torch.numpy())\r\n",
        "print()\r\n",
        "\r\n",
        "# we can do basic operations like +-*/\r\n",
        "y_numpy = np.array([3,4,5.])\r\n",
        "y_torch = torch.tensor([3,4,5.])\r\n",
        "print(\"x+y\")\r\n",
        "print(x_numpy + y_numpy, x_torch + y_torch)\r\n",
        "print()\r\n",
        "\r\n",
        "# many functions that are in numpy are also in pytorch\r\n",
        "print(\"norm\")\r\n",
        "print(np.linalg.norm(x_numpy), torch.norm(x_torch))\r\n",
        "print()\r\n",
        "\r\n",
        "# to apply an operation along a dimension,\r\n",
        "# we use the dim keyword argument instead of axis\r\n",
        "print(\"mean along the 0th dimension\")\r\n",
        "x_numpy = np.array([[1,2],[3,4.]])\r\n",
        "x_torch = torch.tensor([[1,2],[3,4.]])\r\n",
        "print(np.mean(x_numpy, axis=0), torch.mean(x_torch, dim=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_numpy, x_torch\n",
            "[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])\n",
            "\n",
            "to and from numpy and pytorch\n",
            "tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]\n",
            "\n",
            "x+y\n",
            "[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])\n",
            "\n",
            "norm\n",
            "0.37416573867739417 tensor(0.3742)\n",
            "\n",
            "mean along the 0th dimension\n",
            "[2. 3.] tensor([2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg14TysKklp6"
      },
      "source": [
        "### `Tensor.view`\r\n",
        "We can use the `Tensor.view()` function to reshape tensors similarly to `numpy.reshape()`\r\n",
        "\r\n",
        "It can also automatically calculate the correct dimension if a `-1` is passed in. This is useful if we are working with batches, but the batch size is unknown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21MZFezDk8mq",
        "outputId": "56f968f9-41df-42b6-b1bd-7db2ba70444f"
      },
      "source": [
        "# \"MNIST\"\r\n",
        "N, C, W, H = 10000, 3, 28, 28\r\n",
        "X = torch.randn((N, C, W, H))\r\n",
        "\r\n",
        "print(X.shape)\r\n",
        "print(X.view(N, C, 784).shape)\r\n",
        "print(X.view(-1, C, 784).shape) # automatically choose the 0th dimension"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 3, 28, 28])\n",
            "torch.Size([10000, 3, 784])\n",
            "torch.Size([10000, 3, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRluZU_toFm-"
      },
      "source": [
        "### `BROADCASTING SEMANTICS`\r\n",
        "Two tensors are “broadcastable” if the following rules hold:\r\n",
        "\r\n",
        "Each tensor has at least one dimension.\r\n",
        "\r\n",
        "When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8JzLh4JoKsM",
        "outputId": "7a944281-8834-41d7-e5fe-d57b5a376f4b"
      },
      "source": [
        "# PyTorch operations support NumPy Broadcasting Semantics.\r\n",
        "x=torch.empty(5,1,4,1)\r\n",
        "y=torch.empty(  3,1,1)\r\n",
        "print((x+y).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 4, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrh1ufRbshjD"
      },
      "source": [
        "## Computation graphs\r\n",
        "\r\n",
        "What's special about PyTorch's `tensor` object is that it implicitly creates a computation graph in the background. A computation graph is a a way of writing a mathematical expression as a graph. There is an algorithm to compute the gradients of all the variables of a computation graph in time on the same order it is to compute the function itself.\r\n",
        "\r\n",
        "Consider the expression $e=(a+b)*(b+1)$ with values $a=2, b=1$. We can draw the evaluated computation graph as\r\n",
        "<br>\r\n",
        "<br>\r\n",
        "\r\n",
        "In PyTorch, we can write this as"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEJBy41auMvR"
      },
      "source": [
        "![tree-img](https://colah.github.io/posts/2015-08-Backprop/img/tree-eval.png)\r\n",
        "\r\n",
        "[source](https://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea85KbAjub8z",
        "outputId": "c38fbcd6-3f02-4976-b72b-3f54b0c938bd"
      },
      "source": [
        "a = torch.tensor(2.0, requires_grad=True) # we set requires_grad=True to let PyTorch know to keep the graph\r\n",
        "b = torch.tensor(1.0, requires_grad=True)\r\n",
        "c = a + b\r\n",
        "d = b + 1\r\n",
        "e = c * d\r\n",
        "print('c', c)\r\n",
        "print('d', d)\r\n",
        "print('e', e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c tensor(3., grad_fn=<AddBackward0>)\n",
            "d tensor(2., grad_fn=<AddBackward0>)\n",
            "e tensor(6., grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xpfGMVBuelo"
      },
      "source": [
        "We can see that PyTorch kept track of the computation graph for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v572PndTuhlj"
      },
      "source": [
        "## CUDA SEMANTICS\r\n",
        "It's easy cupy tensor from cpu to gpu or from g"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhzcQLbEuvBa",
        "outputId": "0690faae-2029-4426-d8a5-7bf98d48a361"
      },
      "source": [
        "cpu = torch.device(\"cpu\")\r\n",
        "gpu = torch.device(\"cuda\")\r\n",
        "\r\n",
        "x = torch.rand(10)\r\n",
        "print(x)\r\n",
        "x = x.to(gpu)\r\n",
        "print(x)\r\n",
        "x = x.to(cpu)\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
            "        0.1897])\n",
            "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
            "        0.1897], device='cuda:0')\n",
            "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
            "        0.1897])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXM_KT7svLwe"
      },
      "source": [
        "## PyTorch as an auto grad framework\r\n",
        "\r\n",
        "Now that we have seen that PyTorch keeps the graph around for us, let's use it to compute some gradients for us.\r\n",
        "\r\n",
        "Consider the function $f(x) = (x-2)^2$.\r\n",
        "\r\n",
        "Q: Compute $\\frac{d}{dx} f(x)$ and then compute $f'(1)$.\r\n",
        "\r\n",
        "We make a `backward()` call on the leaf variable (`y`) in the computation, computing all the gradients of `y` at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y91t74ufvQ7l",
        "outputId": "5d17de49-bc06-48fe-9727-fc807ef552c8"
      },
      "source": [
        "def f(x):\r\n",
        "    return (x-2)**2\r\n",
        "\r\n",
        "def fp(x):\r\n",
        "    return 2*(x-2)\r\n",
        "\r\n",
        "x = torch.tensor([1.0], requires_grad=True)\r\n",
        "\r\n",
        "y = f(x)\r\n",
        "y.backward()\r\n",
        "\r\n",
        "print('Analytical f\\'(x):', fp(x))\r\n",
        "print('PyTorch\\'s f\\'(x):', x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analytical f'(x): tensor([-2.], grad_fn=<MulBackward0>)\n",
            "PyTorch's f'(x): tensor([-2.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmq6FHvcvWFW"
      },
      "source": [
        "It can also find gradients of functions.\r\n",
        "\r\n",
        "Let $w = [w_1, w_2]^T$\r\n",
        "\r\n",
        "Consider $g(w) = 2w_1w_2 + w_2\\cos(w_1)$\r\n",
        "\r\n",
        "Q: Compute $\\nabla_w g(w)$ and verify $\\nabla_w g([\\pi,1]) = [2, \\pi - 1]^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUVQ5LWDvXYU",
        "outputId": "119b3ed3-dc3b-4235-d24a-4ad1ea107427"
      },
      "source": [
        "def g(w):\r\n",
        "    return 2*w[0]*w[1] + w[1]*torch.cos(w[0])\r\n",
        "\r\n",
        "def grad_g(w):\r\n",
        "    return torch.tensor([2*w[1] - w[1]*torch.sin(w[0]), 2*w[0] + torch.cos(w[0])])\r\n",
        "\r\n",
        "w = torch.tensor([np.pi, 1], requires_grad=True)\r\n",
        "\r\n",
        "z = g(w)\r\n",
        "z.backward()\r\n",
        "\r\n",
        "print('Analytical grad g(w)', grad_g(w))\r\n",
        "print('PyTorch\\'s grad g(w)', w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analytical grad g(w) tensor([2.0000, 5.2832])\n",
            "PyTorch's grad g(w) tensor([2.0000, 5.2832])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDJ_8-ELvyno"
      },
      "source": [
        "## Using the gradients\r\n",
        "Now that we have gradients, we can use our favorite optimization algorithm: gradient descent!\r\n",
        "\r\n",
        "Let $f$ the same function we defined above.\r\n",
        "\r\n",
        "Q: What is the value of $x$ that minimizes $f$?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDaTurfBv7OL",
        "outputId": "f8bff311-a500-4be1-e392-b0a8f762d7c9"
      },
      "source": [
        "x = torch.tensor([5.0], requires_grad=True)\r\n",
        "step_size = 0.25\r\n",
        "\r\n",
        "print('iter,\\tx,\\tf(x),\\tf\\'(x),\\tf\\'(x) pytorch')\r\n",
        "for i in range(15):\r\n",
        "    y = f(x)\r\n",
        "    y.backward() # compute the gradient\r\n",
        "    \r\n",
        "    print('{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}'.format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))\r\n",
        "    \r\n",
        "    x.data = x.data - step_size * x.grad # perform a GD update step\r\n",
        "    \r\n",
        "    # We need to zero the grad variable since the backward()\r\n",
        "    # call accumulates the gradients in .grad instead of overwriting.\r\n",
        "    # The detach_() is for efficiency. You do not need to worry too much about it.\r\n",
        "    x.grad.detach_()\r\n",
        "    x.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tx,\tf(x),\tf'(x),\tf'(x) pytorch\n",
            "0,\t5.000,\t9.000,\t6.000,\t6.000\n",
            "1,\t3.500,\t2.250,\t3.000,\t3.000\n",
            "2,\t2.750,\t0.562,\t1.500,\t1.500\n",
            "3,\t2.375,\t0.141,\t0.750,\t0.750\n",
            "4,\t2.188,\t0.035,\t0.375,\t0.375\n",
            "5,\t2.094,\t0.009,\t0.188,\t0.188\n",
            "6,\t2.047,\t0.002,\t0.094,\t0.094\n",
            "7,\t2.023,\t0.001,\t0.047,\t0.047\n",
            "8,\t2.012,\t0.000,\t0.023,\t0.023\n",
            "9,\t2.006,\t0.000,\t0.012,\t0.012\n",
            "10,\t2.003,\t0.000,\t0.006,\t0.006\n",
            "11,\t2.001,\t0.000,\t0.003,\t0.003\n",
            "12,\t2.001,\t0.000,\t0.001,\t0.001\n",
            "13,\t2.000,\t0.000,\t0.001,\t0.001\n",
            "14,\t2.000,\t0.000,\t0.000,\t0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzSSEh2Kt6L2"
      },
      "source": [
        "# Linear Regression\r\n",
        "\r\n",
        "Now, instead of minimizing a made-up function, lets minimize a loss function on some made-up data.\r\n",
        "\r\n",
        "We will implement Gradient Descent in order to solve the task of linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AO79sMGuJUe",
        "outputId": "8bc76161-9467-4f34-dcf1-85395d91df4a"
      },
      "source": [
        "# make a simple linear dataset with some noise\r\n",
        "\r\n",
        "d = 2\r\n",
        "n = 50\r\n",
        "X = torch.randn(n,d)\r\n",
        "true_w = torch.tensor([[-1.0], [2.0]])\r\n",
        "y = X @ true_w + torch.randn(n,1) * 0.1\r\n",
        "print('X shape', X.shape)\r\n",
        "print('y shape', y.shape)\r\n",
        "print('w shape', true_w.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape torch.Size([50, 2])\n",
            "y shape torch.Size([50, 1])\n",
            "w shape torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltGalFhsuSi0"
      },
      "source": [
        "### Note: dimensions\r\n",
        "PyTorch does a lot of operations on batches of data. The convention is to have your data be of size $(N, d)$ where $N$ is the size of the batch of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSKQKhOauZtb"
      },
      "source": [
        "### Sanity check\r\n",
        "To verify PyTorch is computing the gradients correctly, let's recall the gradient for the RSS objective:\r\n",
        "\r\n",
        "$$\\nabla_w \\mathcal{L}_{RSS}(w; X) = \\nabla_w\\frac{1}{n} ||y - Xw||_2^2 = -\\frac{2}{n}X^T(y-Xw)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SXzqVbbub83",
        "outputId": "fbe5e2e5-38c6-4afa-e32c-c62fb3a2b59f"
      },
      "source": [
        "# define a linear model with no bias\r\n",
        "def model(X, w):\r\n",
        "    return X @ w\r\n",
        "\r\n",
        "# the residual sum of squares loss function\r\n",
        "def rss(y, y_hat):\r\n",
        "    return torch.norm(y - y_hat)**2 / n\r\n",
        "\r\n",
        "# analytical expression for the gradient\r\n",
        "def grad_rss(X, y, w):\r\n",
        "    return -2*X.t() @ (y - X @ w) / n\r\n",
        "\r\n",
        "w = torch.tensor([[1.], [0]], requires_grad=True)\r\n",
        "y_hat = model(X, w)\r\n",
        "\r\n",
        "loss = rss(y, y_hat)\r\n",
        "loss.backward()\r\n",
        "\r\n",
        "print('Analytical gradient', grad_rss(X, y, w).detach().view(2).numpy())\r\n",
        "print('PyTorch\\'s gradient', w.grad.view(2).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analytical gradient [ 4.342543  -3.5023162]\n",
            "PyTorch's gradient [ 4.342543 -3.502316]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1X5dln2uhNA"
      },
      "source": [
        "Now that we've seen PyTorch is doing the right think, let's use the gradients!\r\n",
        "\r\n",
        "## Linear regression using GD with automatically computed derivatives\r\n",
        "\r\n",
        "We will now use the gradients to run the gradient descent algorithm.\r\n",
        "\r\n",
        "Note: This example is an illustration to connect ideas we have seen before to PyTorch's way of doing things. We will see how to do this in the \"PyTorchic\" way in the next example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoloSqGOuu_V",
        "outputId": "b3138740-612c-454f-8e9d-9c9dd44a50c6"
      },
      "source": [
        "step_size = 0.1\r\n",
        "\r\n",
        "print('iter,\\tloss,\\tw')\r\n",
        "for i in range(20):\r\n",
        "    y_hat = model(X, w)\r\n",
        "    loss = rss(y, y_hat)\r\n",
        "    \r\n",
        "    loss.backward() # compute the gradient of the loss\r\n",
        "    \r\n",
        "    w.data = w.data - step_size * w.grad # do a gradient descent step\r\n",
        "    \r\n",
        "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), w.view(2).detach().numpy()))\r\n",
        "    \r\n",
        "    # We need to zero the grad variable since the backward()\r\n",
        "    # call accumulates the gradients in .grad instead of overwriting.\r\n",
        "    # The detach_() is for efficiency. You do not need to worry too much about it.\r\n",
        "    w.grad.detach()\r\n",
        "    w.grad.zero_()\r\n",
        "\r\n",
        "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\r\n",
        "print('estimated w\\t', w.view(2).detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss,\tw\n",
            "0,\t7.82,\t[0.13149136 0.70046324]\n",
            "1,\t2.84,\t[-0.11822014  0.9229876 ]\n",
            "2,\t1.84,\t[-0.31444427  1.1054724 ]\n",
            "3,\t1.19,\t[-0.4684834  1.2552956]\n",
            "4,\t0.77,\t[-0.58927345  1.3784461 ]\n",
            "5,\t0.50,\t[-0.68387645  1.4797904 ]\n",
            "6,\t0.33,\t[-0.75787055  1.563287  ]\n",
            "7,\t0.22,\t[-0.8156596  1.632159 ]\n",
            "8,\t0.15,\t[-0.86071837  1.6890337 ]\n",
            "9,\t0.10,\t[-0.89578694  1.736055  ]\n",
            "10,\t0.07,\t[-0.9230244  1.7749742]\n",
            "11,\t0.05,\t[-0.94413096  1.8072236 ]\n",
            "12,\t0.03,\t[-0.9604442  1.8339758]\n",
            "13,\t0.02,\t[-0.9730157  1.8561921]\n",
            "14,\t0.02,\t[-0.9826713  1.8746614]\n",
            "15,\t0.01,\t[-0.99005884  1.8900318 ]\n",
            "16,\t0.01,\t[-0.99568594  1.9028363 ]\n",
            "17,\t0.01,\t[-0.99994993  1.913514  ]\n",
            "18,\t0.01,\t[-1.0031612  1.9224268]\n",
            "19,\t0.01,\t[-1.0055621  1.9298735]\n",
            "\n",
            "true w\t\t [-1.  2.]\n",
            "estimated w\t [-1.0055621  1.9298735]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOtQFIy3u1LZ"
      },
      "source": [
        "## torch.nn.Module\r\n",
        "\r\n",
        "`Module` is PyTorch's way of performing operations on tensors. Modules are implemented as subclasses of the `torch.nn.Module` class. All modules are callable and can be composed together to create complex functions.\r\n",
        "\r\n",
        "[`torch.nn` docs](https://pytorch.org/docs/stable/nn.html)\r\n",
        "\r\n",
        "Note: most of the functionality implemented for modules can be accessed in a functional form via `torch.nn.functional`, but these require you to create and manage the weight tensors yourself.\r\n",
        "\r\n",
        "[`torch.nn.functional` docs](https://pytorch.org/docs/stable/nn.html#torch-nn-functional)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yqRK0h4u5kA"
      },
      "source": [
        "### Linear Module\r\n",
        "The bread and butter of modules is the Linear module which does a linear transformation with a bias. It takes the input and output dimensions as parameters, and creates the weights in the object.\r\n",
        "\r\n",
        "Unlike how we initialized our $w$ manually, the Linear module automatically initializes the weights randomly. For minimizing non convex loss functions (e.g. training neural networks), initialization is important and can affect results. If training isn't working as well as expected, one thing to try is manually initializing the weights to something different from the default. PyTorch implements some common initializations in `torch.nn.init`.\r\n",
        "\r\n",
        "[`torch.nn.init` docs](https://pytorch.org/docs/stable/nn.html#torch-nn-init)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge2AYW5iu_8E",
        "outputId": "dfd4deea-6f92-4b03-9f3d-764e5af53aab"
      },
      "source": [
        "d_in = 3\r\n",
        "d_out = 4\r\n",
        "linear_module = nn.Linear(d_in, d_out)\r\n",
        "\r\n",
        "example_tensor = torch.tensor([[1.,2,3], [4,5,6]])\r\n",
        "# applys a linear transformation to the data\r\n",
        "transformed = linear_module(example_tensor)\r\n",
        "print('example_tensor', example_tensor.shape)\r\n",
        "print('transormed', transformed.shape)\r\n",
        "print()\r\n",
        "print('We can see that the weights exist in the background\\n')\r\n",
        "print('W:', linear_module.weight)\r\n",
        "print('b:', linear_module.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example_tensor torch.Size([2, 3])\n",
            "transormed torch.Size([2, 4])\n",
            "\n",
            "We can see that the weights exist in the background\n",
            "\n",
            "W: Parameter containing:\n",
            "tensor([[ 0.5260,  0.4925, -0.0887],\n",
            "        [ 0.3944,  0.4080,  0.2182],\n",
            "        [-0.1409,  0.0518,  0.3034],\n",
            "        [ 0.0913,  0.2452, -0.2616]], requires_grad=True)\n",
            "b: Parameter containing:\n",
            "tensor([0.5021, 0.0118, 0.1383, 0.4757], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtONRcFQv2ZZ"
      },
      "source": [
        "### Activation functions\r\n",
        "PyTorch implements a number of activation functions including but not limited to `ReLU`, `Tanh`, and `Sigmoid`. Since they are modules, they need to be instantiated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5Esvemv5Z1",
        "outputId": "697ce89c-f51c-4a96-c153-051fd91ac04b"
      },
      "source": [
        "activation_fn = nn.ReLU() # we instantiate an instance of the ReLU module\r\n",
        "example_tensor = torch.tensor([-1.0, 1.0, 0.0])\r\n",
        "activated = activation_fn(example_tensor)\r\n",
        "print('example_tensor', example_tensor)\r\n",
        "print('activated', activated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example_tensor tensor([-1.,  1.,  0.])\n",
            "activated tensor([0., 1., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwS-n5XUwCGc"
      },
      "source": [
        "### Sequential\r\n",
        "\r\n",
        "Many times, we want to compose Modules together. `torch.nn.Sequential` provides a good interface for composing simple modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVijsB9XwFaZ",
        "outputId": "8be23e0e-fe1c-41ab-d79e-5bc44184309d"
      },
      "source": [
        "d_in = 3\r\n",
        "d_hidden = 4\r\n",
        "d_out = 1\r\n",
        "model = torch.nn.Sequential(\r\n",
        "                            nn.Linear(d_in, d_hidden),\r\n",
        "                            nn.Tanh(),\r\n",
        "                            nn.Linear(d_hidden, d_out),\r\n",
        "                            nn.Sigmoid()\r\n",
        "                           )\r\n",
        "\r\n",
        "example_tensor = torch.tensor([[1.,2,3],[4,5,6]])\r\n",
        "transformed = model(example_tensor)\r\n",
        "print('transformed', transformed.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "transformed torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbzmb7vLwKNg"
      },
      "source": [
        "Note: we can access *all* of the parameters (of any `nn.Module`) with the `parameters()` method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQF2yt8CwMC_",
        "outputId": "cba2012c-9966-4811-86f4-e05a55b8d34c"
      },
      "source": [
        "params = model.parameters()\r\n",
        "\r\n",
        "for param in params:\r\n",
        "    print(param)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3128,  0.2707, -0.3952],\n",
            "        [ 0.1285,  0.1777, -0.4675],\n",
            "        [ 0.0452, -0.5630, -0.1999],\n",
            "        [ 0.5431,  0.0524,  0.1126]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2683, -0.2361,  0.2769, -0.1380], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.4902, -0.0928, -0.2907,  0.0734]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0394], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL1ZQlD1wW1m"
      },
      "source": [
        "### Loss functions\r\n",
        "PyTorch implements many common loss functions including `MSELoss` and `CrossEntropyLoss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nwlGtvRwas0",
        "outputId": "5473762a-4549-46c8-fe54-d37704e7deea"
      },
      "source": [
        "mse_loss_fn = nn.MSELoss()\r\n",
        "\r\n",
        "input = torch.tensor([[0., 0, 0]])\r\n",
        "target = torch.tensor([[1., 0, -1]])\r\n",
        "\r\n",
        "loss = mse_loss_fn(input, target)\r\n",
        "\r\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6667)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irZqKc7vweF0"
      },
      "source": [
        "## torch.optim\r\n",
        "PyTorch implements a number of gradient-based optimization methods in `torch.optim`, including Gradient Descent. At the minimum, it takes in the model parameters and a learning rate.\r\n",
        "\r\n",
        "Optimizers do not compute the gradients for you, so you must call `backward()` yourself. You also must call the `optim.zero_grad()` function before calling `backward()` since by default PyTorch does and inplace add to the `.grad` member variable rather than overwriting it.\r\n",
        "\r\n",
        "This does both the `detach_()` and `zero_()` calls on all tensor's `grad` variables.\r\n",
        "\r\n",
        "[`torch.optim` docs](https://pytorch.org/docs/stable/optim.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPuLETRxwiZz",
        "outputId": "f7dcd5c0-e495-4de4-8dcc-f5bb4b00578a"
      },
      "source": [
        "# create a simple model\r\n",
        "model = nn.Linear(1, 1)\r\n",
        "\r\n",
        "# create a simple dataset\r\n",
        "X_simple = torch.tensor([[1.]])\r\n",
        "y_simple = torch.tensor([[2.]])\r\n",
        "\r\n",
        "# create our optimizer\r\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2)\r\n",
        "mse_loss_fn = nn.MSELoss()\r\n",
        "\r\n",
        "y_hat = model(X_simple)\r\n",
        "print('model params before:', model.weight)\r\n",
        "loss = mse_loss_fn(y_hat, y_simple)\r\n",
        "optim.zero_grad()\r\n",
        "loss.backward()\r\n",
        "optim.step()\r\n",
        "print('model params after:', model.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model params before: Parameter containing:\n",
            "tensor([[-0.5487]], requires_grad=True)\n",
            "model params after: Parameter containing:\n",
            "tensor([[-0.5041]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0IxiOdmwnND"
      },
      "source": [
        "As we can see, the parameter was updated in the correct direction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF--n92zwxa7"
      },
      "source": [
        "## Linear regression using GD with automatically computed derivatives and PyTorch's Modules\r\n",
        "\r\n",
        "Now let's combine what we've learned to solve linear regression in a \"PyTorchic\" way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRrf7UjTw0J5",
        "outputId": "22631225-f759-4704-9d7b-523bf6ff8dfa"
      },
      "source": [
        "step_size = 0.1\r\n",
        "\r\n",
        "linear_module = nn.Linear(d, 1, bias=False)\r\n",
        "\r\n",
        "loss_func = nn.MSELoss()\r\n",
        "\r\n",
        "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\r\n",
        "\r\n",
        "print('iter,\\tloss,\\tw')\r\n",
        "\r\n",
        "for i in range(20):\r\n",
        "    y_hat = linear_module(X)\r\n",
        "    loss = loss_func(y_hat, y)\r\n",
        "    optim.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optim.step()\r\n",
        "    \r\n",
        "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\r\n",
        "\r\n",
        "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\r\n",
        "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss,\tw\n",
            "0,\t2.29,\t[-0.3859704  0.8518376]\n",
            "1,\t1.51,\t[-0.53111917  1.0400821 ]\n",
            "2,\t1.00,\t[-0.6439842  1.1957945]\n",
            "3,\t0.67,\t[-0.73155683  1.3247426 ]\n",
            "4,\t0.45,\t[-0.7993402  1.4316461]\n",
            "5,\t0.30,\t[-0.85166246  1.5203714 ]\n",
            "6,\t0.20,\t[-0.8919245  1.5940894]\n",
            "7,\t0.14,\t[-0.9227959  1.6554034]\n",
            "8,\t0.10,\t[-0.9463698  1.7064534]\n",
            "9,\t0.07,\t[-0.9642856  1.749001 ]\n",
            "10,\t0.05,\t[-0.97782534  1.7844973 ]\n",
            "11,\t0.04,\t[-0.98799014  1.8141392 ]\n",
            "12,\t0.03,\t[-0.99556065  1.8389157 ]\n",
            "13,\t0.02,\t[-1.0011443  1.859644 ]\n",
            "14,\t0.02,\t[-1.0052128  1.8770008]\n",
            "15,\t0.01,\t[-1.0081316  1.8915467]\n",
            "16,\t0.01,\t[-1.0101832  1.9037468]\n",
            "17,\t0.01,\t[-1.0115852  1.9139876]\n",
            "18,\t0.01,\t[-1.0125047  1.9225901]\n",
            "19,\t0.01,\t[-1.0130696  1.9298217]\n",
            "\n",
            "true w\t\t [-1.  2.]\n",
            "estimated w\t [-1.0130696  1.9298217]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7JsTw-5w4eP"
      },
      "source": [
        "## Linear regression using SGD \r\n",
        "In the previous examples, we computed the average gradient over the entire dataset (Gradient Descent). We can implement Stochastic Gradient Descent with a simple modification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy6bCxVOw6kt",
        "outputId": "789630f7-c4f1-4f6d-ae18-14a1c7a0abab"
      },
      "source": [
        "step_size = 0.01\r\n",
        "\r\n",
        "linear_module = nn.Linear(d, 1)\r\n",
        "loss_func = nn.MSELoss()\r\n",
        "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\r\n",
        "print('iter,\\tloss,\\tw')\r\n",
        "for i in range(200):\r\n",
        "    rand_idx = np.random.choice(n) # take a random point from the dataset\r\n",
        "    x = X[rand_idx] \r\n",
        "    y_hat = linear_module(x)\r\n",
        "    loss = loss_func(y_hat, y[rand_idx]) # only compute the loss on the single point\r\n",
        "    optim.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optim.step()\r\n",
        "    \r\n",
        "    if i % 20 == 0:\r\n",
        "        print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\r\n",
        "\r\n",
        "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\r\n",
        "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss,\tw\n",
            "0,\t1.65,\t[0.5743579 0.42951  ]\n",
            "20,\t0.34,\t[0.09791921 0.61812305]\n",
            "40,\t0.77,\t[-0.12659666  0.9623728 ]\n",
            "60,\t0.54,\t[-0.35293424  1.3701379 ]\n",
            "80,\t0.19,\t[-0.542525   1.5289117]\n",
            "100,\t0.48,\t[-0.6765383  1.6920214]\n",
            "120,\t0.11,\t[-0.7933236  1.8108759]\n",
            "140,\t0.01,\t[-0.85540015  1.8868232 ]\n",
            "160,\t0.01,\t[-0.917086   1.9103304]\n",
            "180,\t0.01,\t[-0.9536688  1.9182668]\n",
            "\n",
            "true w\t\t [-1.  2.]\n",
            "estimated w\t [-0.9596093  1.9431977]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri0UQAGixATB"
      },
      "source": [
        "# Neural Network Basics in PyTorch\r\n",
        "We will try and fit a simple neural network to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "4gMannRMxCXG",
        "outputId": "6acc2a66-39ce-457b-a11c-aa01aac52936"
      },
      "source": [
        "%matplotlib inline\r\n",
        "\r\n",
        "d = 1\r\n",
        "n = 200\r\n",
        "X = torch.rand(n,d)\r\n",
        "y = 4 * torch.sin(np.pi * X) * torch.cos(6*np.pi*X**2)\r\n",
        "\r\n",
        "plt.scatter(X.numpy(), y.numpy())\r\n",
        "plt.title('plot of $f(x)$')\r\n",
        "plt.xlabel('$x$')\r\n",
        "plt.ylabel('$y$')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz1q2o-NxGN2"
      },
      "source": [
        "Here we define a simple two hidden layer neural network with Tanh activations. There are a few hyper parameters to play with to get a feel for how they change the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACd0fVwdxIC2",
        "outputId": "e66995d6-bcc1-4d6b-c720-eb487c5695bb"
      },
      "source": [
        "# feel free to play with these parameters\r\n",
        "\r\n",
        "step_size = 0.05\r\n",
        "n_epochs = 6000\r\n",
        "n_hidden_1 = 32\r\n",
        "n_hidden_2 = 32\r\n",
        "d_out = 1\r\n",
        "\r\n",
        "neural_network = nn.Sequential(\r\n",
        "                            nn.Linear(d, n_hidden_1), \r\n",
        "                            nn.Tanh(),\r\n",
        "                            nn.Linear(n_hidden_1, n_hidden_2),\r\n",
        "                            nn.Tanh(),\r\n",
        "                            nn.Linear(n_hidden_2, d_out)\r\n",
        "                            )\r\n",
        "\r\n",
        "loss_func = nn.MSELoss()\r\n",
        "\r\n",
        "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size)\r\n",
        "print('iter,\\tloss')\r\n",
        "for i in range(n_epochs):\r\n",
        "    y_hat = neural_network(X)\r\n",
        "    loss = loss_func(y_hat, y)\r\n",
        "    optim.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optim.step()\r\n",
        "    \r\n",
        "    if i % (n_epochs // 10) == 0:\r\n",
        "        print('{},\\t{:.2f}'.format(i, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss\n",
            "0,\t3.92\n",
            "600,\t3.77\n",
            "1200,\t2.76\n",
            "1800,\t1.07\n",
            "2400,\t0.91\n",
            "3000,\t0.72\n",
            "3600,\t0.45\n",
            "4200,\t0.13\n",
            "4800,\t0.10\n",
            "5400,\t0.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "iz-zJw2exTgu",
        "outputId": "037c06df-3b52-4592-fa58-d3b320efd20f"
      },
      "source": [
        "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\r\n",
        "y_hat = neural_network(X_grid)\r\n",
        "plt.scatter(X.numpy(), y.numpy())\r\n",
        "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\r\n",
        "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\r\n",
        "plt.xlabel('$x$')\r\n",
        "plt.ylabel('$y$')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGrRgnFuxXxh"
      },
      "source": [
        "# Things that might help on the homework\r\n",
        "\r\n",
        "## Brief Sidenote: Momentum\r\n",
        "\r\n",
        "There are other optimization algorithms besides stochastic gradient descent. One is a modification of SGD called momentum. We won't get into it here, but if you would like to read more [here](https://distill.pub/2017/momentum/) is a good place to start.\r\n",
        "\r\n",
        "We only change the step size and add the momentum keyword argument to the optimizer. Notice how it reduces the training loss in fewer iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LujptKorxaPz",
        "outputId": "2710fe93-ff24-4d97-caa7-91481a86e748"
      },
      "source": [
        "# feel free to play with these parameters\r\n",
        "\r\n",
        "step_size = 0.05\r\n",
        "momentum = 0.9\r\n",
        "n_epochs = 1500\r\n",
        "n_hidden_1 = 32\r\n",
        "n_hidden_2 = 32\r\n",
        "d_out = 1\r\n",
        "\r\n",
        "neural_network = nn.Sequential(\r\n",
        "                            nn.Linear(d, n_hidden_1), \r\n",
        "                            nn.Tanh(),\r\n",
        "                            nn.Linear(n_hidden_1, n_hidden_2),\r\n",
        "                            nn.Tanh(),\r\n",
        "                            nn.Linear(n_hidden_2, d_out)\r\n",
        "                            )\r\n",
        "\r\n",
        "loss_func = nn.MSELoss()\r\n",
        "\r\n",
        "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size, momentum=momentum)\r\n",
        "print('iter,\\tloss')\r\n",
        "for i in range(n_epochs):\r\n",
        "    y_hat = neural_network(X)\r\n",
        "    loss = loss_func(y_hat, y)\r\n",
        "    optim.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optim.step()\r\n",
        "    \r\n",
        "    if i % (n_epochs // 10) == 0:\r\n",
        "        print('{},\\t{:.2f}'.format(i, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss\n",
            "0,\t4.06\n",
            "150,\t3.52\n",
            "300,\t0.88\n",
            "450,\t0.17\n",
            "600,\t0.05\n",
            "750,\t0.04\n",
            "900,\t0.01\n",
            "1050,\t0.00\n",
            "1200,\t0.00\n",
            "1350,\t0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "RvozspZ6xe4L",
        "outputId": "1b3f9691-3a61-4344-9397-61e0f7b00222"
      },
      "source": [
        "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\r\n",
        "y_hat = neural_network(X_grid)\r\n",
        "plt.scatter(X.numpy(), y.numpy())\r\n",
        "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\r\n",
        "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\r\n",
        "plt.xlabel('$x$')\r\n",
        "plt.ylabel('$y$')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCG-hTQrxorS"
      },
      "source": [
        "## CrossEntropyLoss\r\n",
        "So far, we have been considering regression tasks and have used the [MSELoss](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss) module. For the homework, we will be performing a classification task and will use the cross entropy loss.\r\n",
        "\r\n",
        "PyTorch implements a version of the cross entropy loss in one module called [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss). Its usage is slightly different than MSE, so we will break it down here. \r\n",
        "\r\n",
        "- input: The first parameter to CrossEntropyLoss is the output of our network. It expects a *real valued* tensor of dimensions $(N,C)$ where $N$ is the minibatch size and $C$ is the number of classes. In our case $N=3$ and $C=2$. The values along the second dimension correspond to raw unnormalized scores for each class. The CrossEntropyLoss module does the softmax calculation for us, so we do not need to apply our own softmax to the output of our neural network.\r\n",
        "- output: The second parameter to CrossEntropyLoss is the true label. It expects an *integer valued* tensor of dimension $(N)$. The integer at each element corresponds to the correct class. In our case, the \"correct\" class labels are class 0, class 1, and class 1.\r\n",
        "\r\n",
        "Try out the loss function on three toy predictions. The true class labels are $y=[1,1,0]$. The first two examples correspond to predictions that are \"correct\" in that they have higher raw scores for the correct class. The second example is \"more confident\" in the prediction, leading to a smaller loss. The last two examples are incorrect predictions with lower and higher confidence respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b72Rgz7yxsHZ",
        "outputId": "bc2b7bf1-1010-43c3-adf1-10d9d0715f8b"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "input = torch.tensor([[-1., 1],[-1, 1],[1, -1]]) # raw scores correspond to the correct class\r\n",
        "# input = torch.tensor([[-3., 3],[-3, 3],[3, -3]]) # raw scores correspond to the correct class with higher confidence\r\n",
        "# input = torch.tensor([[1., -1],[1, -1],[-1, 1]]) # raw scores correspond to the incorrect class\r\n",
        "# input = torch.tensor([[3., -3],[3, -3],[-3, 3]]) # raw scores correspond to the incorrect class with incorrectly placed confidence\r\n",
        "\r\n",
        "target = torch.tensor([1, 1, 0])\r\n",
        "output = loss(input, target)\r\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1269)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIH7Zh2GxvaG"
      },
      "source": [
        "## Learning rate schedulers\r\n",
        "\r\n",
        "Often we do not want to use a fixed learning rate throughout all training. PyTorch offers learning rate schedulers to change the learning rate over time. Common strategies include multiplying the lr by a constant every epoch (e.g. 0.9) and halving the learning rate when the training loss flattens out.\r\n",
        "\r\n",
        "See the [learning rate scheduler docs](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) for usage and examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD45oqyTxx37"
      },
      "source": [
        "## Convolutions\r\n",
        "When working with images, we often want to use convolutions to extract features using convolutions. PyTorch implments this for us in the `torch.nn.Conv2d` module. It expects the input to have a specific dimension $(N, C_{in}, H_{in}, W_{in})$ where $N$ is batch size, $C_{in}$ is the number of channels the image has, and $H_{in}, W_{in}$ are the image height and width respectively.\r\n",
        "\r\n",
        "We can modify the convolution to have different properties with the parameters:\r\n",
        "- kernel_size\r\n",
        "- stride\r\n",
        "- padding\r\n",
        "\r\n",
        "They can change the output dimension so be careful.\r\n",
        "\r\n",
        "See the [`torch.nn.Conv2d` docs](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFOpGZBox14J"
      },
      "source": [
        "To illustrate what the `Conv2d` module is doing, let's set the conv weights manually to a Gaussian blur kernel.\r\n",
        "\r\n",
        "We can see that it applies the kernel to the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l7pUweNx5IR"
      },
      "source": [
        "# an entire mnist digit\r\n",
        "image = np.array([0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.3803922 , 0.37647063, 0.3019608 ,0.46274513, 0.2392157 , 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.3529412 , 0.5411765 , 0.9215687 ,0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,0.9215687 , 0.74509805, 0.08235294, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.54901963,0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.7411765 , 0.09019608, 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.8862746 , 0.9960785 , 0.81568635,0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,0.08235294, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.14901961, 0.32156864, 0.0509804 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.13333334,0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.32941177, 0.9960785 ,0.9960785 , 0.9176471 , 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.4156863 , 0.6156863 ,0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.94117653, 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.26666668, 0.4666667 , 0.86274517,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.14509805, 0.73333335,0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,0.9960785 , 0.9960785 , 0.45882356, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,0.45098042, 0.34901962, 0.12156864, 0., 0.,0., 0., 0.7843138 , 0.9960785 , 0.9450981 ,0.16078432, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.6627451 , 0.9960785 ,0.6901961 , 0.24313727, 0., 0., 0.,0., 0., 0., 0., 0.18823531,0.9058824 , 0.9960785 , 0.9176471 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.07058824, 0.48627454, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.32941177, 0.9960785 , 0.9960785 ,0.6509804 , 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.8235295 , 0.9803922 , 0.9960785 ,0.65882355, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.34901962, 0.9843138 , 0.9450981 ,0.3372549 , 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.01960784,0.8078432 , 0.96470594, 0.6156863 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.01568628, 0.45882356, 0.27058825,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.], dtype=np.float32)\r\n",
        "image_torch = torch.from_numpy(image).view(1, 1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "GC9gqPLlx8Wc",
        "outputId": "b640338c-2b60-466a-bf5c-7d9d254ed500"
      },
      "source": [
        "# a gaussian blur kernel\r\n",
        "gaussian_kernel = torch.tensor([[1., 2, 1],[2, 4, 2],[1, 2, 1]]) / 16.0\r\n",
        "\r\n",
        "conv = nn.Conv2d(1, 1, 3)\r\n",
        "# manually set the conv weight\r\n",
        "conv.weight.data[:] = gaussian_kernel\r\n",
        "\r\n",
        "convolved = conv(image_torch)\r\n",
        "\r\n",
        "plt.title('original image')\r\n",
        "plt.imshow(image_torch.view(28,28).detach().numpy())\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.title('blurred image')\r\n",
        "plt.imshow(convolved.view(26,26).detach().numpy())\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gotx0YHqyC0A"
      },
      "source": [
        "As we can see, the image is blurred as expected. \r\n",
        "\r\n",
        "In practice, we learn many kernels at a time. In this example, we take in an RGB image (3 channels) and output a 16 channel image. After an activation function, that could be used as input to another `Conv2d` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLyQBz3FyIIy",
        "outputId": "a7142d1e-38c4-40ce-80bc-15f34fba7a32"
      },
      "source": [
        "im_channels = 3 # if we are working with RGB images, there are 3 input channels, with black and white, 1\r\n",
        "out_channels = 16 # this is a hyperparameter we can tune\r\n",
        "kernel_size = 3 # this is another hyperparameter we can tune\r\n",
        "batch_size = 4\r\n",
        "image_width = 32\r\n",
        "image_height = 32\r\n",
        "\r\n",
        "im = torch.randn(batch_size, im_channels, image_width, image_height)\r\n",
        "\r\n",
        "m = nn.Conv2d(im_channels, out_channels, kernel_size)\r\n",
        "convolved = m(im) # it is a module so we can call it\r\n",
        "\r\n",
        "print('im shape', im.shape)\r\n",
        "print('convolved im shape', convolved.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im shape torch.Size([4, 3, 32, 32])\n",
            "convolved im shape torch.Size([4, 16, 30, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8VE1V2xyMBv"
      },
      "source": [
        "## Useful links:\r\n",
        "- [60 minute PyTorch Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\r\n",
        "- [PyTorch Docs](https://pytorch.org/docs/stable/index.html)\r\n",
        "- [Lecture notes on Auto-Diff](https://courses.cs.washington.edu/courses/cse446/19wi/notes/auto-diff.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MEKbcHkyOk7"
      },
      "source": [
        "Custom Datasets, DataLoaders\r\n",
        "===================================================\r\n",
        "This is modified from pytorch official tutorial.\r\n",
        "**Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`\r\n",
        "\r\n",
        "A lot of effort in solving any machine learning problem goes in to\r\n",
        "preparing the data. PyTorch provides many tools to make data loading\r\n",
        "easy and hopefully, to make your code more readable. In this tutorial,\r\n",
        "we will see how to load and preprocess/augment data from a non trivial\r\n",
        "dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UerkIci1yWdE"
      },
      "source": [
        "Dataset class\r\n",
        "-------------\r\n",
        "\r\n",
        "``torch.utils.data.Dataset`` is an abstract class representing a\r\n",
        "dataset.\r\n",
        "Your custom dataset should inherit ``Dataset`` and override the following\r\n",
        "methods:\r\n",
        "\r\n",
        "-  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.\r\n",
        "-  ``__getitem__`` to support the indexing such that ``dataset[i]`` can\r\n",
        "   be used to get $i$\\ th sample\r\n",
        "\r\n",
        "Let's create a dataset class for our face landmarks dataset. We will\r\n",
        "read the csv in ``__init__`` but leave the reading of images to\r\n",
        "``__getitem__``. This is memory efficient because all the images are not\r\n",
        "stored in the memory at once but read as required.\r\n",
        "\r\n",
        "Sample of our dataset will be a dict\r\n",
        "``{'image': image, 'landmarks': landmarks}``. Our dataset will take an\r\n",
        "optional argument ``transform`` so that any required processing can be\r\n",
        "applied on the sample. We will see the usefulness of ``transform`` in the\r\n",
        "next section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIzN43UgyY85"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "class FakeDataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self, x, y):\r\n",
        "        self.x = x\r\n",
        "        self.y = y\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.x)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw5GdeP3ykMQ"
      },
      "source": [
        "However, we are losing a lot of features by using a simple ``for`` loop to\r\n",
        "iterate over the data. In particular, we are missing out on:\r\n",
        "\r\n",
        "-  Batching the data\r\n",
        "-  Shuffling the data\r\n",
        "-  Load the data in parallel using ``multiprocessing`` workers.\r\n",
        "\r\n",
        "``torch.utils.data.DataLoader`` is an iterator which provides all these\r\n",
        "features. Parameters used below should be clear. One parameter of\r\n",
        "interest is ``collate_fn``. You can specify how exactly the samples need\r\n",
        "to be batched using ``collate_fn``. However, default collate should work\r\n",
        "fine for most use cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aPzdObCypSB",
        "outputId": "9b94998c-e2a4-406e-c2a5-4be19dad1ad4"
      },
      "source": [
        "x = np.random.rand(100, 10)\r\n",
        "y = np.random.rand(100)\r\n",
        "\r\n",
        "dataset = FakeDataset(x, y)\r\n",
        "dataloader = DataLoader(dataset, batch_size=4,\r\n",
        "                        shuffle=True, num_workers=4)\r\n",
        "\r\n",
        "for i_batch, sample_batched in enumerate(dataloader):\r\n",
        "    print(i_batch, sample_batched)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [tensor([[0.7299, 0.6399, 0.5307, 0.3669, 0.8802, 0.2936, 0.1531, 0.4092, 0.2909,\n",
            "         0.9733],\n",
            "        [0.1864, 0.8668, 0.2255, 0.4177, 0.7093, 0.8264, 0.8240, 0.0656, 0.1143,\n",
            "         0.6391],\n",
            "        [0.4753, 0.4926, 0.4595, 0.9881, 0.9667, 0.9884, 0.6675, 0.1673, 0.0083,\n",
            "         0.0377],\n",
            "        [0.3275, 0.9519, 0.4797, 0.6329, 0.3010, 0.4499, 0.0319, 0.3484, 0.7486,\n",
            "         0.4976]], dtype=torch.float64), tensor([0.3033, 0.1933, 0.7881, 0.0286], dtype=torch.float64)]\n",
            "1 [tensor([[0.4098, 0.0563, 0.5053, 0.9396, 0.6260, 0.6925, 0.1186, 0.4357, 0.6965,\n",
            "         0.7626],\n",
            "        [0.9878, 0.5644, 0.9747, 0.1329, 0.6884, 0.2989, 0.4496, 0.5509, 0.0066,\n",
            "         0.4876],\n",
            "        [0.1209, 0.0944, 0.3105, 0.7302, 0.1299, 0.4542, 0.3695, 0.1626, 0.4883,\n",
            "         0.0155],\n",
            "        [0.0412, 0.9999, 0.6860, 0.1620, 0.1127, 0.0526, 0.7301, 0.3691, 0.5892,\n",
            "         0.8359]], dtype=torch.float64), tensor([0.9089, 0.4448, 0.3218, 0.3420], dtype=torch.float64)]\n",
            "2 [tensor([[0.4618, 0.4775, 0.4352, 0.9928, 0.2119, 0.0740, 0.7224, 0.8868, 0.5236,\n",
            "         0.0055],\n",
            "        [0.2523, 0.5704, 0.9769, 0.7493, 0.6006, 0.8080, 0.8184, 0.2344, 0.6277,\n",
            "         0.7121],\n",
            "        [0.1929, 0.3506, 0.0921, 0.3103, 0.8524, 0.3823, 0.2444, 0.6609, 0.4500,\n",
            "         0.2035],\n",
            "        [0.1100, 0.9307, 0.8565, 0.9234, 0.6466, 0.5139, 0.1449, 0.2484, 0.2549,\n",
            "         0.0574]], dtype=torch.float64), tensor([0.5149, 0.2400, 0.1026, 0.9179], dtype=torch.float64)]\n",
            "3 [tensor([[0.3403, 0.8986, 0.5617, 0.5326, 0.4641, 0.9167, 0.0352, 0.2361, 0.3085,\n",
            "         0.1437],\n",
            "        [0.3076, 0.4840, 0.8262, 0.3136, 0.8811, 0.7817, 0.4943, 0.6647, 0.7805,\n",
            "         0.0711],\n",
            "        [0.6524, 0.3432, 0.4155, 0.8317, 0.3899, 0.0163, 0.3177, 0.7584, 0.8076,\n",
            "         0.3475],\n",
            "        [0.5914, 0.0166, 0.4447, 0.2936, 0.9296, 0.2357, 0.6398, 0.4538, 0.9728,\n",
            "         0.1115]], dtype=torch.float64), tensor([0.1851, 0.1167, 0.8038, 0.9089], dtype=torch.float64)]\n",
            "4 [tensor([[0.7548, 0.6793, 0.0386, 0.4215, 0.0259, 0.2891, 0.9065, 0.5613, 0.2778,\n",
            "         0.1135],\n",
            "        [0.1500, 0.9295, 0.1664, 0.6619, 0.8176, 0.0323, 0.2159, 0.4852, 0.3602,\n",
            "         0.8844],\n",
            "        [0.0268, 0.8455, 0.2843, 0.8445, 0.5389, 0.1842, 0.5174, 0.8963, 0.2922,\n",
            "         0.1556],\n",
            "        [0.0125, 0.4836, 0.6855, 0.1898, 0.8947, 0.6190, 0.9878, 0.4671, 0.1395,\n",
            "         0.4836]], dtype=torch.float64), tensor([0.5848, 0.7884, 0.2029, 0.7850], dtype=torch.float64)]\n",
            "5 [tensor([[0.7784, 0.7866, 0.7890, 0.5986, 0.7744, 0.1240, 0.2171, 0.0932, 0.7143,\n",
            "         0.0164],\n",
            "        [0.8327, 0.2055, 0.8221, 0.2619, 0.9454, 0.2427, 0.3983, 0.4542, 0.3291,\n",
            "         0.8491],\n",
            "        [0.4153, 0.4503, 0.4965, 0.1709, 0.3076, 0.2496, 0.0985, 0.4603, 0.1050,\n",
            "         0.2533],\n",
            "        [0.9150, 0.2385, 0.4682, 0.4484, 0.0434, 0.6068, 0.5771, 0.9923, 0.2797,\n",
            "         0.5785]], dtype=torch.float64), tensor([0.3460, 0.2201, 0.9313, 0.1896], dtype=torch.float64)]\n",
            "6 [tensor([[0.3300, 0.4613, 0.0464, 0.1918, 0.6575, 0.6818, 0.4975, 0.7177, 0.1854,\n",
            "         0.1349],\n",
            "        [0.6884, 0.7677, 0.4220, 0.6848, 0.4153, 0.6101, 0.4259, 0.9906, 0.7406,\n",
            "         0.9721],\n",
            "        [0.4085, 0.4291, 0.0595, 0.4663, 0.4566, 0.4094, 0.3923, 0.9878, 0.7551,\n",
            "         0.5323],\n",
            "        [0.2809, 0.2436, 0.7457, 0.2624, 0.4324, 0.2166, 0.5708, 0.3626, 0.3313,\n",
            "         0.1276]], dtype=torch.float64), tensor([0.9038, 0.9983, 0.1245, 0.6274], dtype=torch.float64)]\n",
            "7 [tensor([[0.3357, 0.4213, 0.2279, 0.7748, 0.0124, 0.5663, 0.4240, 0.2727, 0.0986,\n",
            "         0.3977],\n",
            "        [0.8361, 0.9204, 0.4035, 0.8303, 0.6870, 0.8541, 0.7166, 0.9591, 0.3616,\n",
            "         0.4006],\n",
            "        [0.2161, 0.7080, 0.0823, 0.8506, 0.6371, 0.7456, 0.4735, 0.8046, 0.5081,\n",
            "         0.5017],\n",
            "        [0.1219, 0.8618, 0.5016, 0.4410, 0.2339, 0.4093, 0.9565, 0.0725, 0.7881,\n",
            "         0.1762]], dtype=torch.float64), tensor([0.0949, 0.7814, 0.2192, 0.0383], dtype=torch.float64)]\n",
            "8 [tensor([[0.1830, 0.6266, 0.6450, 0.6935, 0.2313, 0.4099, 0.8946, 0.7944, 0.7788,\n",
            "         0.2935],\n",
            "        [0.8152, 0.9537, 0.8881, 0.5767, 0.3812, 0.8709, 0.1662, 0.2689, 0.9501,\n",
            "         0.9570],\n",
            "        [0.1615, 0.8459, 0.6392, 0.8360, 0.3150, 0.9412, 0.7139, 0.8753, 0.6244,\n",
            "         0.8858],\n",
            "        [0.0914, 0.9125, 0.7608, 0.6511, 0.8120, 0.1939, 0.3496, 0.1728, 0.3441,\n",
            "         0.5239]], dtype=torch.float64), tensor([0.9227, 0.1824, 0.7912, 0.9173], dtype=torch.float64)]\n",
            "9 [tensor([[0.4010, 0.4071, 0.7084, 0.6094, 0.4190, 0.0880, 0.7047, 0.8450, 0.1906,\n",
            "         0.7871],\n",
            "        [0.4894, 0.2787, 0.7328, 0.8260, 0.0072, 0.4422, 0.9973, 0.1693, 0.0781,\n",
            "         0.0534],\n",
            "        [0.1877, 0.8325, 0.7022, 0.7525, 0.7294, 0.7312, 0.4374, 0.6332, 0.3066,\n",
            "         0.0164],\n",
            "        [0.3033, 0.2126, 0.3115, 0.6762, 0.8204, 0.3404, 0.0025, 0.2192, 0.1457,\n",
            "         0.1140]], dtype=torch.float64), tensor([0.6439, 0.9870, 0.9422, 0.5600], dtype=torch.float64)]\n",
            "10 [tensor([[0.5755, 0.7310, 0.3480, 0.8357, 0.8273, 0.2108, 0.5344, 0.8285, 0.2193,\n",
            "         0.0525],\n",
            "        [0.1830, 0.2685, 0.3785, 0.1926, 0.1750, 0.6524, 0.0470, 0.5768, 0.9558,\n",
            "         0.3030],\n",
            "        [0.1356, 0.9622, 0.2630, 0.1778, 0.8344, 0.8143, 0.2168, 0.7930, 0.4488,\n",
            "         0.3728],\n",
            "        [0.8240, 0.6985, 0.2775, 0.4298, 0.7508, 0.1379, 0.8566, 0.0306, 0.8726,\n",
            "         0.8238]], dtype=torch.float64), tensor([0.3101, 0.8383, 0.3682, 0.5828], dtype=torch.float64)]\n",
            "11 [tensor([[0.8626, 0.6300, 0.1504, 0.8357, 0.9513, 0.0875, 0.2037, 0.5602, 0.2392,\n",
            "         0.5785],\n",
            "        [0.8701, 0.2061, 0.9199, 0.7679, 0.6270, 0.5381, 0.3273, 0.0358, 0.4629,\n",
            "         0.3571],\n",
            "        [0.7893, 0.7050, 0.8763, 0.1537, 0.4035, 0.9407, 0.0621, 0.8590, 0.3954,\n",
            "         0.5220],\n",
            "        [0.5532, 0.8223, 0.0802, 0.9806, 0.9618, 0.2711, 0.4122, 0.8605, 0.3360,\n",
            "         0.4145]], dtype=torch.float64), tensor([0.9843, 0.1120, 0.3812, 0.5941], dtype=torch.float64)]\n",
            "12 [tensor([[0.0055, 0.0339, 0.2460, 0.7344, 0.1402, 0.0574, 0.8856, 0.7105, 0.4294,\n",
            "         0.0999],\n",
            "        [0.3366, 0.3766, 0.7566, 0.7523, 0.4238, 0.9513, 0.0314, 0.0214, 0.4260,\n",
            "         0.2304],\n",
            "        [0.3007, 0.5288, 0.2442, 0.3173, 0.0848, 0.3862, 0.9510, 0.7286, 0.6011,\n",
            "         0.0519],\n",
            "        [0.7655, 0.2148, 0.5616, 0.6376, 0.2002, 0.0533, 0.0030, 0.8495, 0.8213,\n",
            "         0.4480]], dtype=torch.float64), tensor([0.8429, 0.6126, 0.0197, 0.1861], dtype=torch.float64)]\n",
            "13 [tensor([[0.3706, 0.2455, 0.1819, 0.3769, 0.2376, 0.7937, 0.8245, 0.1926, 0.0789,\n",
            "         0.7087],\n",
            "        [0.5254, 0.5427, 0.3628, 0.6960, 0.2886, 0.9353, 0.9689, 0.6012, 0.1582,\n",
            "         0.4367],\n",
            "        [0.4259, 0.1018, 0.0954, 0.1481, 0.3224, 0.1089, 0.6246, 0.3205, 0.0639,\n",
            "         0.2193],\n",
            "        [0.4102, 0.1455, 0.8229, 0.7937, 0.6920, 0.6642, 0.1776, 0.6291, 0.0601,\n",
            "         0.5506]], dtype=torch.float64), tensor([0.7332, 0.1656, 0.1441, 0.6731], dtype=torch.float64)]\n",
            "14 [tensor([[0.1006, 0.5021, 0.4176, 0.9280, 0.0712, 0.1559, 0.1696, 0.1280, 0.5047,\n",
            "         0.8401],\n",
            "        [0.7273, 0.2927, 0.6264, 0.0172, 0.8470, 0.8845, 0.8372, 0.6170, 0.1041,\n",
            "         0.6958],\n",
            "        [0.8274, 0.3138, 0.3992, 0.9346, 0.5357, 0.0272, 0.2833, 0.6078, 0.8637,\n",
            "         0.3413],\n",
            "        [0.5618, 0.1706, 0.4135, 0.7749, 0.8082, 0.0753, 0.2220, 0.5096, 0.3851,\n",
            "         0.8348]], dtype=torch.float64), tensor([0.2553, 0.3612, 0.5246, 0.4685], dtype=torch.float64)]\n",
            "15 [tensor([[0.8995, 0.8026, 0.0095, 0.5831, 0.1146, 0.4983, 0.6000, 0.9879, 0.6547,\n",
            "         0.9260],\n",
            "        [0.8884, 0.4877, 0.6329, 0.6263, 0.6320, 0.7045, 0.3195, 0.3841, 0.9593,\n",
            "         0.2860],\n",
            "        [0.4821, 0.9311, 0.9325, 0.5611, 0.9733, 0.9202, 0.8805, 0.5094, 0.3387,\n",
            "         0.2823],\n",
            "        [0.3824, 0.8406, 0.7120, 0.1866, 0.5284, 0.3931, 0.3991, 0.5207, 0.9336,\n",
            "         0.6751]], dtype=torch.float64), tensor([0.9865, 0.9467, 0.5159, 0.5503], dtype=torch.float64)]\n",
            "16 [tensor([[0.8038, 0.5939, 0.2823, 0.4960, 0.9016, 0.1506, 0.3035, 0.2967, 0.4604,\n",
            "         0.4290],\n",
            "        [0.8275, 0.0831, 0.8764, 0.3083, 0.9285, 0.0967, 0.8587, 0.1045, 0.2944,\n",
            "         0.0276],\n",
            "        [0.9312, 0.4660, 0.1075, 0.3356, 0.0728, 0.6576, 0.9510, 0.4153, 0.4846,\n",
            "         0.4244],\n",
            "        [0.3649, 0.4502, 0.4806, 0.8996, 0.4097, 0.6211, 0.2890, 0.8240, 0.4099,\n",
            "         0.7209]], dtype=torch.float64), tensor([0.4047, 0.7050, 0.6437, 0.2625], dtype=torch.float64)]\n",
            "17 [tensor([[0.9815, 0.7615, 0.0315, 0.2393, 0.9707, 0.1807, 0.6645, 0.9342, 0.0663,\n",
            "         0.4530],\n",
            "        [0.6277, 0.0886, 0.6954, 0.5705, 0.0357, 0.9796, 0.8187, 0.3179, 0.0654,\n",
            "         0.0154],\n",
            "        [0.9092, 0.3946, 0.0589, 0.6904, 0.1723, 0.3965, 0.8337, 0.6334, 0.6733,\n",
            "         0.3250],\n",
            "        [0.1842, 0.8327, 0.5381, 0.5614, 0.1766, 0.3946, 0.9296, 0.8930, 0.1785,\n",
            "         0.7056]], dtype=torch.float64), tensor([0.1126, 0.9432, 0.6074, 0.3301], dtype=torch.float64)]\n",
            "18 [tensor([[0.8933, 0.8932, 0.5026, 0.8808, 0.2539, 0.8462, 0.3022, 0.5633, 0.8363,\n",
            "         0.3315],\n",
            "        [0.5716, 0.8413, 0.7261, 0.8521, 0.8210, 0.6213, 0.9814, 0.6401, 0.9176,\n",
            "         0.9446],\n",
            "        [0.0916, 0.5313, 0.2077, 0.7243, 0.7656, 0.5569, 0.2398, 0.4772, 0.5166,\n",
            "         0.6155],\n",
            "        [0.8796, 0.3532, 0.1296, 0.5720, 0.2520, 0.5586, 0.2290, 0.6347, 0.4743,\n",
            "         0.3507]], dtype=torch.float64), tensor([0.5176, 0.9442, 0.7274, 0.9826], dtype=torch.float64)]\n",
            "19 [tensor([[0.8288, 0.5044, 0.7484, 0.5466, 0.5561, 0.9304, 0.0946, 0.0411, 0.9721,\n",
            "         0.6885],\n",
            "        [0.6711, 0.1294, 0.9840, 0.7129, 0.4768, 0.1295, 0.1699, 0.8166, 0.1888,\n",
            "         0.6158],\n",
            "        [0.1008, 0.3056, 0.8560, 0.9626, 0.8457, 0.4799, 0.1085, 0.8674, 0.9302,\n",
            "         0.3065],\n",
            "        [0.7929, 0.8750, 0.2901, 0.2755, 0.9480, 0.6514, 0.2391, 0.1752, 0.5290,\n",
            "         0.1912]], dtype=torch.float64), tensor([0.9138, 0.9417, 0.8031, 0.2563], dtype=torch.float64)]\n",
            "20 [tensor([[0.7927, 0.9481, 0.7394, 0.6647, 0.4164, 0.9068, 0.4608, 0.9244, 0.2833,\n",
            "         0.8592],\n",
            "        [0.9911, 0.6582, 0.1700, 0.5174, 0.8015, 0.0714, 0.8662, 0.0224, 0.8664,\n",
            "         0.3882],\n",
            "        [0.4138, 0.8597, 0.2734, 0.5270, 0.2356, 0.8953, 0.6913, 0.4750, 0.6981,\n",
            "         0.8005],\n",
            "        [0.2560, 0.2524, 0.6295, 0.1996, 0.7914, 0.2180, 0.1181, 0.6182, 0.4729,\n",
            "         0.3008]], dtype=torch.float64), tensor([0.7308, 0.7503, 0.9879, 0.9000], dtype=torch.float64)]\n",
            "21 [tensor([[0.4290, 0.5590, 0.4631, 0.7568, 0.7571, 0.5170, 0.0422, 0.1990, 0.6521,\n",
            "         0.6765],\n",
            "        [0.6040, 0.0091, 0.9736, 0.9721, 0.9516, 0.5171, 0.6455, 0.6825, 0.1415,\n",
            "         0.8912],\n",
            "        [0.2166, 0.3644, 0.8316, 0.7961, 0.5470, 0.7051, 0.2640, 0.4010, 0.5947,\n",
            "         0.5322],\n",
            "        [0.4877, 0.0156, 0.2263, 0.4509, 0.2057, 0.4076, 0.0755, 0.4848, 0.9168,\n",
            "         0.8827]], dtype=torch.float64), tensor([0.3407, 0.1466, 0.6430, 0.4058], dtype=torch.float64)]\n",
            "22 [tensor([[0.1951, 0.0182, 0.2687, 0.0124, 0.9533, 0.2365, 0.7655, 0.6966, 0.0441,\n",
            "         0.4104],\n",
            "        [0.0931, 0.5769, 0.6763, 0.6201, 0.5092, 0.7188, 0.1523, 0.5806, 0.1696,\n",
            "         0.5970],\n",
            "        [0.7726, 0.4031, 0.7194, 0.6481, 0.8232, 0.2398, 0.7997, 0.2111, 0.2108,\n",
            "         0.9862],\n",
            "        [0.1934, 0.8813, 0.0853, 0.1268, 0.6577, 0.6394, 0.3029, 0.1309, 0.3206,\n",
            "         0.3208]], dtype=torch.float64), tensor([0.9706, 0.4588, 0.9123, 0.2477], dtype=torch.float64)]\n",
            "23 [tensor([[0.7834, 0.6403, 0.6852, 0.2207, 0.4793, 0.7839, 0.5015, 0.8851, 0.1206,\n",
            "         0.3842],\n",
            "        [0.7083, 0.0662, 0.3609, 0.5579, 0.3714, 0.8201, 0.2972, 0.9235, 0.3503,\n",
            "         0.4142],\n",
            "        [0.0066, 0.1176, 0.4757, 0.5757, 0.3711, 0.4035, 0.6166, 0.2843, 0.1738,\n",
            "         0.0358],\n",
            "        [0.8139, 0.1490, 0.9299, 0.6129, 0.5462, 0.3276, 0.1525, 0.8341, 0.3352,\n",
            "         0.8669]], dtype=torch.float64), tensor([0.2825, 0.9724, 0.5229, 0.4703], dtype=torch.float64)]\n",
            "24 [tensor([[0.0875, 0.2225, 0.3801, 0.2263, 0.3371, 0.8353, 0.7697, 0.4595, 0.2872,\n",
            "         0.0834],\n",
            "        [0.0981, 0.7663, 0.0282, 0.6467, 0.2491, 0.2940, 0.9218, 0.3358, 0.8001,\n",
            "         0.5784],\n",
            "        [0.7647, 0.6885, 0.4693, 0.6570, 0.8722, 0.6438, 0.0415, 0.5401, 0.4872,\n",
            "         0.0090],\n",
            "        [0.9863, 0.4248, 0.9973, 0.0325, 0.2116, 0.9035, 0.5127, 0.6365, 0.0148,\n",
            "         0.8470]], dtype=torch.float64), tensor([0.7609, 0.4941, 0.7930, 0.6811], dtype=torch.float64)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmvpgMHgytF1"
      },
      "source": [
        "Mixed Presision Training\r\n",
        "===================================================\r\n",
        "**Author**: `Chi-Liang Liu <https://liangtaiwan.github.io>`\r\n",
        "**Ref**: https://github.com/NVIDIA/apex\r\n",
        "Using mixed precision to train your networks can be:\r\n",
        "- 2-4x faster\r\n",
        "- memory-efficient\r\n",
        "in only 3 lines of Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQgROOnyywko"
      },
      "source": [
        "# Apex \r\n",
        "\r\n",
        "NVIDIA-maintained utilities to streamline mixed precision and distributed training in Pytorch. Some of the code here will be included in upstream Pytorch eventually. The intention of Apex is to make up-to-date utilities available to users as quickly as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s_4rp7-yy98"
      },
      "source": [
        "## apex.amp\r\n",
        "\r\n",
        "Amp allows users to easily experiment with different pure and mixed precision modes.\r\n",
        "Commonly-used default modes are chosen by\r\n",
        "selecting an \"optimization level\" or ``opt_level``; each ``opt_level`` establishes a set of\r\n",
        "properties that govern Amp's implementation of pure or mixed precision training.\r\n",
        "Finer-grained control of how a given ``opt_level`` behaves can be achieved by passing values for\r\n",
        "particular properties directly to ``amp.initialize``.  These manually specified values\r\n",
        "override the defaults established by the ``opt_level``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnHbXzihy4dY"
      },
      "source": [
        "from apex import amp\r\n",
        "\r\n",
        "# Declare model and optimizer as usual, with default (FP32) precision\r\n",
        "model = torch.nn.Linear(10, 100).cuda()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\r\n",
        "\r\n",
        "# Allow Amp to perform casts as required by the opt_level\r\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\r\n",
        "...\r\n",
        "# loss.backward() becomes:\r\n",
        "with amp.scale_loss(loss, optimizer) as scaled_loss:\r\n",
        "    scaled_loss.backward()\r\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}